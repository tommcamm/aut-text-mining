{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY891NWn2K-P"
      },
      "source": [
        "# Text Mining - Assignment\n",
        "Due 7th june by midnight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup for Colab\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  print('Running on CoLab, downloading all the data')\n",
        "  # download the pre-processed datasets\n",
        "  ## -nc avoid to download the file if already present, -P is the directory where the file will be placed\n",
        "  !wget -nc https://github.com/tommcamm/aut-text-mining/raw/main/Assignment/code/PreProcessed/students_preprocessed.pkl.gz -P PreProcessed # students pre-processed\n",
        "  !wget -nc https://github.com/tommcamm/aut-text-mining/raw/main/Assignment/code/PreProcessed/under_20s_preprocessed.pkl.gz -P PreProcessed # under 20s pre-processed\n",
        "  !wget -nc https://github.com/tommcamm/aut-text-mining/raw/main/Assignment/code/PreProcessed/females_preprocessed.pkl.gz -P PreProcessed # females pre-processed\n",
        "  !wget -nc https://github.com/tommcamm/aut-text-mining/raw/main/Assignment/code/PreProcessed/males_preprocessed.pkl.gz -P PreProcessed # males pre-processed\n",
        "\n",
        "  # Download the test data - two files\n",
        "  !wget -nc https://raw.githubusercontent.com/tommcamm/aut-text-mining/main/Assignment/code/TestDir/23676.male.33.Technology.Scorpio.xml -P TestDir\n",
        "  !wget -nc https://raw.githubusercontent.com/tommcamm/aut-text-mining/main/Assignment/code/TestDir/5114.male.25.indUnk.Scorpio.xml -P TestDir\n",
        "else:\n",
        "  print('Not running on CoLab, skipping download')\n",
        "  # For this step I assume the data is already there\n",
        "  directory_path = './Assignment2BlogData/blogs'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABbRHDBa7Ui2",
        "outputId": "28b28fa1-362e-4e05-f915-0789463e9421"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n",
            "File ‘PreProcessed/students_preprocessed.pkl.gz’ already there; not retrieving.\n",
            "\n",
            "File ‘PreProcessed/under_20s_preprocessed.pkl.gz’ already there; not retrieving.\n",
            "\n",
            "File ‘PreProcessed/females_preprocessed.pkl.gz’ already there; not retrieving.\n",
            "\n",
            "File ‘PreProcessed/males_preprocessed.pkl.gz’ already there; not retrieving.\n",
            "\n",
            "File ‘TestDir/23676.male.33.Technology.Scorpio.xml’ already there; not retrieving.\n",
            "\n",
            "File ‘TestDir/5114.male.25.indUnk.Scorpio.xml’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnqgXm7l8lbR"
      },
      "source": [
        "## Data cleaning\n",
        "The following steps will be applied to the dataset to ensure it is cleaned.\n",
        "1. Remove Non-ASCII Characters: Ensures text is ASCII encoded.\n",
        "2. Remove Punctuation: Removes any punctuation marks.\n",
        "3. Lowercase Conversion: Converts all text to lowercase.\n",
        "4. Remove Stopwords: Removes common stopwords that do not contribute to the meaning of the text.\n",
        "5. Tokenization: Splits text into individual words.\n",
        "6. Lemmatization: Reduces words to their base or root form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOnkMyOK86bB",
        "outputId": "a7e7b1a9-fe25-450f-bf6c-2754d97d12a7",
        "ExecuteTime": {
          "end_time": "2024-06-01T07:18:07.997432Z",
          "start_time": "2024-06-01T07:18:06.026130Z"
        }
      },
      "source": [
        "import spacy\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "import chardet\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "# this command must be run before: python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "#spacy.require_gpu() # Ensure is using GPU\n",
        "#spacy.require_cpu()\n",
        "\n",
        "# Text pre-processing pipeline\n",
        "def preprocess_text(text):\n",
        "    # 1. We remove all XML tags from the document (along with the date)\n",
        "    text = re.sub(r'<date>.*?</date>', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'<[^>]+>', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'urlLink', '', text, flags=re.DOTALL) # Remove links\n",
        "\n",
        "    text = text.encode('ascii', 'ignore').decode('ascii') # Remove non ASCII characters\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text) # Remove punctuation\n",
        "\n",
        "\n",
        "    text = text.lower() # Lowercasing to make it case-insensitive\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    tagged_tokens = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Remove stopwords and perform lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Map POS tag to first character lemmatize() accepts\n",
        "    def get_wordnet_pos(tag):\n",
        "        if tag.startswith('J'):\n",
        "            return wordnet.ADJ  # adjective\n",
        "        elif tag.startswith('V'):\n",
        "            return wordnet.VERB  # verb\n",
        "        elif tag.startswith('N'):\n",
        "            return wordnet.NOUN  # noun\n",
        "        elif tag.startswith('R'):\n",
        "            return wordnet.ADV  # adverb\n",
        "        else:\n",
        "            return wordnet.NOUN  # default to noun\n",
        "\n",
        "    cleaned_tokens = [\n",
        "        (lemmatizer.lemmatize(token, get_wordnet_pos(tag)), tag)\n",
        "        for token, tag in tagged_tokens\n",
        "        if token not in stopwords.words('english')\n",
        "    ]\n",
        "\n",
        "    return cleaned_tokens\n",
        "\n",
        "# Pre-Process pipeline using spacy for GPU\n",
        "def preprocess_text_spacy(text):\n",
        "    # 1. Remove all XML tags from the document (along with the date)\n",
        "    text = re.sub(r'<date>.*?</date>', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'<[^>]+>', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'urlLink', '', text, flags=re.DOTALL) # Remove links\n",
        "\n",
        "    # Convert to ASCII and lowercasing to make it case-insensitive\n",
        "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
        "    text = text.lower()\n",
        "\n",
        "    # Process the text with SpaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Remove stopwords and perform lemmatization\n",
        "    cleaned_tokens = [\n",
        "        (token.lemma_, token.pos_)\n",
        "        for token in doc\n",
        "        if not token.is_stop and token.is_alpha\n",
        "    ]\n",
        "\n",
        "    return cleaned_tokens\n",
        "\n",
        "def process_file(filepath):\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            raw_data = f.read()\n",
        "            result = chardet.detect(raw_data)\n",
        "            encoding = result['encoding']\n",
        "            text = raw_data.decode(encoding)\n",
        "            cleaned_text = preprocess_text_spacy(text)\n",
        "            return cleaned_text, None\n",
        "    except Exception as e:\n",
        "        return None, (filepath, str(e))\n",
        "\n",
        "def extract_and_preprocess_text_from_directory(directory_path, filter_func=None):\n",
        "    text_data = []\n",
        "    failed_files = []\n",
        "    filepaths = [os.path.join(directory_path, filename) for filename in os.listdir(directory_path)]\n",
        "\n",
        "    if filter_func:\n",
        "        filepaths = [fp for fp in filepaths if filter_func(fp)]\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = {executor.submit(process_file, filepath): filepath for filepath in filepaths}\n",
        "        with tqdm(total=len(filepaths), desc=\"Processing files\") as pbar:\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                cleaned_text, error = future.result()\n",
        "                if cleaned_text:\n",
        "                    text_data.append(cleaned_text)\n",
        "                else:\n",
        "                    failed_files.append(error)\n",
        "                pbar.update(1)\n",
        "    return text_data, failed_files\n",
        "\n",
        "# Helper functions\n",
        "def get_tokens_without_pos(doc):\n",
        "    \"\"\"\n",
        "    Extracts tokens without POS tags from the document.\n",
        "\n",
        "    :param doc: List of tuples (token, pos_tag)\n",
        "    :return: List of tokens\n",
        "    \"\"\"\n",
        "    return [token for token, _ in doc]\n",
        "\n",
        "def get_text_from_tokens(doc):\n",
        "    \"\"\"\n",
        "    Constructs a string from tokens without POS tags.\n",
        "\n",
        "    :param doc: List of tuples (token, pos_tag)\n",
        "    :return: String of concatenated tokens\n",
        "    \"\"\"\n",
        "    tokens_only = get_tokens_without_pos(doc)\n",
        "    return ' '.join(tokens_only)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-01T07:18:08.906994Z",
          "start_time": "2024-06-01T07:18:07.997488Z"
        },
        "id": "Hlyula1x6kMh",
        "outputId": "6e5cdbe3-8e5b-4bfe-cd4e-365306f29b6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Test of the pre-processor on one file\n",
        "test_dir = 'TestDir'\n",
        "text_data_test, failed_data_test = extract_and_preprocess_text_from_directory(test_dir)\n",
        "\n",
        "print('\\nTEST RESULTS (23676, 5114)')\n",
        "for doc in text_data_test:\n",
        "    print(\"-> \", get_text_from_tokens(doc))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing files: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TEST RESULTS (23676, 5114)\n",
            "->  hello run finally end smooth win static congrat gil box quick sell ni wednesday hold xping goodness pm edt usual thursday friday hold genkai madness head mold paper saturday conclude genkai explosure madness bomb coal sunday run hunt key genkai thank shari deft handling get genkai alliance friday saturday genkai experience mildly horrible instead excruciatingly horrible friday start alliance people eventually grow shrink night go manage obtain need exoray mold mere time read blame dynastey aggro nearly nest case time saturday turn trek eldeime dyn manage aggro half mob glacier personal small group night able dispatch come mere hour reward papyrus death level shari bad outing genkai item probably post hopefully check newly create forum arrr p xp fun night shorty whm rest swashbuckler enjoy individual pursuit generally successul sharkky run jungle yhoator try find specific word actually find search party dispatch dynastey spend time fishing realize moon favor try luck cooking dog dog need tum shari go level lvl arm stack mithkabob toothpick intrepid taru brave wild sarutabaruta realize wonder count shari beg o meter reset skellington run maze shakrami search new place farm instead find lowbie die horrible death hand link stonega require license operate tomorrow genkai madness hello primary user device go lay schedule day let know problem comment find game etc soon messageboard forum stay tune courtesy eck wednesday pm jeuno xp party thursday friday pm jeuno genkai hunt crawler nest eldieme necropolis garlaige citadel saturday pm jeuno genkai hunt continue sunday monday pm jeuno xp party tuesday tuesday july pm static run follow propose static lineup shari blm whm shortcake whm blm sakari brd whm skellington pld war dynastey drk war sharkky thf nin roundabout level jeuno ready play pm bad thing happen shari minor confusion death pick xp night woot heh ok static run friday night pm edt need blogger account post message email lot spam think good subject line post desire static run conflict suggest run post comment thursday run shari thank tonight tuesday head come pm pdt fall asleep congratulation dynastey finish drk weekend dynastey jobom skellington hand kick ass vaa huja erudite shari call supermeganukemasu reinforcement dyn die time second time breeze end victorious congrats dyn let know waterga ii bitch spread word amen congratulation successful bcnm run member time meeting static party monday july pm edt issue post comment shari man baby yeah post merely introduce blog scheduling information ffxi lakshmi server swashbuckler linkshell static party shari skellington purpose act like pirate leveling generally have good time bcnm party schedule follow thank gang return regularly schedule program xping night tue thur week jeuno exception makeup genkai run pre empt xping say night\n",
            "->  slashdot raise lot interesting thought banner ad idea let user control ad delivery allow user comment ad merchant cool frontline documentary feature mindjack advisory board member douglas rushkoff pbs tonight check local listing time atms dispense music logic entirely pay nominal fee music medium pay likely buy stuff pc chair start squeak day ago drive nut new york press lenghty article post dotcom crash scene worth read francis collins surprising thing human genome filmspeed great movie download free man particular favorite film time sale stb nvidia zx mb accelerator agp nec cd rom drive interesting trade consider start upload stuff radio station welcome listen cable dsl high require feed late special issue excellent examination video game contribution carl steadman steven johnson justin hall miss new dvd maltese falcon personal homepage long weblog come fashion manage update couple time year hope bit successful big thank bopjet host mindjack register report war drive wireless equivalent war dialing instead have modem dial thousand network drive range wireless net wireless equip laptop hack away relate late issue cio great feature wireless short documentary digital filmmaking star war episode ii rumour parent company brill content announce merger early monday apparently print magazine fold call brill inside content website form medium central roll right tongue destroy monster survivor monster island money mothra spend time play beta version atmosphere adobe new environment software think couple quick impression interested vr spend bit time work vrml think inherant problem vrml attention give community build cool place people interact easily environment go forth web page involve project try solve problem vrml anybody remember terra vista far like atmosphere appear address problem product maybe adobe muscle gain wide acceptance thank able receive fax suprisingly local phone number fredericton choose new york city area code want whirl number suppose work long trail procrastination end redesign site quotable mindjack mike sugarbaker review lemon patience lengthy rumination brilliant madman lemon read mindjack probably sort thing right mindjack feature link section month netlife magazine online scan big yahoo news yesterday tim koogle step ceo miss forecast quarter today stock tumble time report trogan room coffee machine webcam go offline good later year pot museum look like big news yahoo later today new issue mindjack magazine online feature live concert review original photo good box sinutab describe day sinus pain headache congestion itchy watery eye ugh end free chronicle demise free stuff net sure like direction feed turn filter new weblog link outside content feature prominently feed original content clear difference filter plastic hey jon lebkowsky start blog coolness wisdom find look like new palmos pda trg look mighty impressive official launch rumor monday price reasonably upgrade palmpilot personal stick figure fight action like see evan williams blogger trellix deal happen mean need logo maybe website email work toy announce trellix license pyra blogger technology give pyra needed cash infusion dan bricklin fascinating account deal happen site recently get monkey dvd excellent worth pick include feature length documentary hamster factor tale monkey making film redesign report economist business editor chris anderson name editor wire replace katrina heron new issue digital web magazine today lot interesting stuff reason vegetarian justin japan story picture screwy go computer thing crash mouse stutter skip slow crawl get nagging feeling go complete format reinstall window want point rumor automatic medium trouble automatic company consist feed suck plastic hopefully rumour home underdog amazing resource love computer game hundred game download long available company wealth information game entirely legal think great public service well favorite game gabriel knight great article william gibson observer special japan issue reinvent culture way want great big shoe david bowie write glam today guardian play customize yahoo know new use theme additoin plain color stream video reboot conference feature justin hall dave winer evan williams douglas rushkoff ya think mindjack deep development mode magic blog follow action happen shift design look vaguely familar look good javascript scroll box slooooow hear dove lose souls album year include good list hawksley workman night delicious wolf probably year list cnet video steve job tour apple new retail store be cool news great clip picture new coen brother film man excited redesign think stick sure advertising damn good advertising dsl feed great interview cory doctorow today overlap doctorow day job opencola night job write fiction make unique combination like william gibson launch company sell neural plug stim sim douglas rushkoff frontline documentary merchant cool rebroadcast tonight pbs check local listing set tivo vcr watch dslless day suppose compare company pretty snappy service day dsl feed give official word today sutte foreseeable future go suck look like plastic continue feed suck online year excellent hopefully pull funk come form month jason kottke great picture louvre today great roadtrip article mark frauenfelder magazine half century ago street southern california fill flamboyant tower consumerism spire obelisk beacon transmit neon fortify message optimism family ride car space age tailfin life good marvel modern science make world new tomorrow bill frisell late album blue dream arrive mail today confirm suspect get frisell blogdex spider crawl blog generate list link site buck say blogdex number tomorrow live dangerously hotsynce palmpilot couple month long crape stay tune year webzine conference nyc look like go coverage current issue mindjack look summer reading canadian medium theorist canadian media resource find read boe boe weblog notice link mark cory garage flea market find today man uninstalle mcafee viruscan computer twice fast find virus scanner memory appetite mindjack come keyboard like anymore underwood portable mention day staroffice look like big improvement current version staroffice alternative powerpoint sluggishness mention article stop regularly synapse offiicially open come stop synapse live publicly launch late tonight look conversation go like help join copy word word word arrive day good unintentionally start typewriter collection give underwood portable typewriter near perfect condition yesterday cool stuff pick egyptian painting papyrus estate auction day actually well condition picture make look image find online finally set definite launch date synapse mindjack long development online community monday week stay tune good apod august lagoon nebula color new wallpaper go atlantic canada large flea market sussex new brunswick yesterday get sun burn buck accord site model work great apart stick key find ribbon staple sell kensington videocam yesterday result be webcam reload want be changin holy shit accord advertising age industry standard cease publication blogbuddy look useful window base blogger evhead doc searl weblog discover great weblog village voice feature high speed free peter meyer good article wireless network nyc new mini blog peek recent medium consumption well buy add incentive thing update today davenet great explanation blogger api mean copy word word word magazine way new zealand today good spam dear sir madam supply high quality fly shoe fly shoe let walk normally slide fly sort fashionable product fob price usd pair welcome order look detail photo wood shoe bamoo mat wood flooring aluminu plastic decorate panel etc look good regard long satrap guilin lingui shengpe xiaoxue bamboo wood manufactory address rongshan road lingui guilin guang china tel fax e mail web site mindjack excerpt cory doctorow novel progress eastern standard tribe cory take discussion synapse skip read issue wire miss great private tokyo william gibson coltrane man myth new york times photgraphica absence discover great photolog start call sure pixelpile common thread digital camera come british columbia great space art find object mindjack slashdotte boingboinge prolific david bowie excellent cover america paul simon real audio novemember national novel write month goal write page word novel november think start try write short story month great gallery low res picture take pencam mention cool interface boingboe thank cool blogback comment odyssey yes space geek watch odyssey enter mar orbit cross finger mindjack look writer preferably one commit write article month pay right promise pay soon money interested drop email include sample writing real soon feel free pass think interested special feature new monty python holy grail dvd region encoding canada color close caption widescreen commentary terry gilliam terry jones plus general complaint biting john cleese eric idle michael palin theatrical high definition widescreen presentation pink frilly edge subtitle people like film take shakespeare henry iv ii screen screenplay read screenplay watch film exciting follow killer rabbit feature special version hard hear glorious extra second absolutely free mindless sing along join michael palin terry jones special documentary quest holy grail location use coconut educational film monty python holy grail lego location python genuine min location report bbc film night broadcast december interactive cast directory discover role michael palin play ton terry gilliam original sketch plus poster scene photo hitherto unseen human eye load old rubbish surprise package mystery item specially include mentally challenge director recce budget widescreen letterbox format wait cory doctorow start record audio version story start market market branding billy bailey download find time man matt hinrichs scrubble great illustration synapse join redesign crap order new citizen kane dvd place day today find buck cheap infinite matrix whoohoo mindjack market x examination microsoft marketing xbox windows xp hopefully article jane umami tsunami pinckard justin site turn wonderful resource thing cool japanese get start write anybody want pay watch map territory night great documentary director mark neale kind send run magazine perk thing consist william gibson sit limo musing cyberspace religion review mindjack couple week slashdot effect look like new mindjack today astronomical vision chris mckinstry early cold february morning look highly astigmatic eye professional telescope set jupiter flawed vision long white metal tube finely manufacture piece sophisticated medical equipment let cloud band solar system large planet bright point handful moon mind make feel shadow shock galileo feel see sight redesign mindjack bit load bit fast look well low resolution new week design community review david brake week interview derek powazek new infinite matrix long excerpt cory doctorow new novel magic kingdom liberty square ad hocs staunch conservative magic kingdom preserve wheezing technology face park change daily newcomer old timer rest park support look like successful left corner cory doctorow blog page excuse post blog lately try kick pant x mas break thing go wonderful gallery atari concept illustration boingboing redesign mindjack page bit include entire daily relay blog excerpt denizen new weblog classic gaming creator home underdog mindjack review xircom wireless lan module palm handheld subject cory doctorow interesting year ago sea change computing experience day realize start view computer connect internet fancy game console cum jump typewriter work airplane caf feel wrong feeling deepen magnify thousandfold day get ibook airport base station wireless networking laptop know talk snatch internet air experience will willingly tivo stop watch tv hotel room choose thirty hour custom record programming skip commercial tivo ruin dumb tv ruin wired networking networking keep get well technology movement ad hoc world open base station world haul equip device start hunt network major city chance find block forget g blackberry pale imitation connectivity community wireless real shit fast unmetered insecure control mindjack t shirt available high quality genuine screenprinted shirt cafe press stuff thank brunetto look shirt print highly recommend available mindjack coffee mug feature illustration matt hinrichs cafe press one buy build robot perpetual humanoid model want especially come sound effect video february need day load work suppose blog oranger daily relay run email work let know problem crap email address mess need reach use think mattel make classic electronic football game think amazing thing get atari great little chinese grocery street apartment find try today iron buddha tea good tea try jim lai report digifest new issue mindjack way expectation go digifest pretty picture glitzy art advertising piece possibly cool tech pleasantly surprise breadth depth presentation wednesday night hit medium session get graphic big screen theme international digital medium festival d challenge dimension deem festival success overall end festival apparent speculation constitute fourth dimension spoil ending get way festival original vision local toronto participation quickly expand scope arrival international submission soire keynote attendee snack cater food mingle people dress hip stylishly feel underdressed good casual face cool business card flow like water get ibook osx sure take ajuste impressed far neil gaiman writer answer question worry job security writer good indication writer hate writing good know writer hate writing miserable new mindjack report sxsw interactive jon lebkowksy photo paul bausch year south southwest interactive conference lean mean attend mainly core group edgy net whackadista conference interesting vibe like wow glad goddam dotcom splurge let real depth way compelling ecommerce kind project mbas bring table start call internet industry create concept ipo casino mindjack short break great article douglas rushkoff conform machine read futurefeedforward new york abc news magazine reporter john stossel accidentally decapitate late month shoot segment debunk myth wind power return air wednesday special interview anchor barbara walters amazing story explain walter people survive decapitation let gut determination job real triumph human spirit favorite cory doctorow cory doctorow get new gig eff remind suporte nearly rest march decide donate mindjack t shirt sell eff daily relay finally blogger interim solution probably switch blogger pro moveable type problem sort week mindjack read mcluhan melanie mcbride message dummy age grasp desire believe reinforce trend like usability privilege economy elucidation anticipate well marshall mcluhan whittle big insight sound bite order engage audience lecture hall university toronto help tom wolfe scholarly mcluhan cool media prophet practical strategy anti intellectual time process mcluhan meaning reduce liner absence commentary mcluhan literary philosophical cultural influence way work teach new issue mindjack deal favorite topic robot submission burn baby burn mix cd swap dispraportionate amount bowie reed course click read tracklist mindjack advisory board member douglas rushkoff start blog expect good thing expect criterion collection website excellent similar old criterion go movie cd rom worth check take work run computer seven year fill great essay good move get great interview simon singh author code book new issue mindjack gadzook long time post sorry interview derek powazek new mindjack talk online community book weblog journalism mindjack try new guerrila advertising campaign feel free use ad weblog website come soon mindjack work site mindjack interview warren ellis read comic_strip day comic_strip write want little muscle bite standard issue power fantasy whimsical romance autobiography people thing elf western medium cycle currently creative downturn mean excellent work simply mean personal level little talk comic_strip reflect fact live multicultural society fit global communication net reflect fact pair superman underpant howard rheingold interview npr realaudio link get copy smart mob hope soon mindjack jim lai check art exhibit form billboard transmedia second fame mindjack cybersecurity nosebleed sarah granger security new hype commodity united states visualize drive highway past billboard read big government want big security picture ape beat chest seriously convinced mindjack proper relaunch time bit slow start month get lengthy article lawrence lessig bryan alexander issue plus review neat little digital camera spread word kick miss david bowie concert bbc radio today able find couple song bewlay brother amazing case sit edge site rest assure mindjack relaunch track monday word cbc anniversary special wish start cable channel stuff get syberia post mortem promise new adventure game montreal base developer microid able judge post big fan adventure game traditional kind carry enormous inventory pant explore game pace think lot genre lately plan write soon aside review aforementioned game interested hear thought adventure game think place today favorite game comment bode get work weekend adrenaline vault good shareware justin hall south korea korea televise tv cab tv subway stack stack tiny tiny television able enjoy television time seoul subway television subway instead static ad bulletin board future fun fun watch soon annoying normal brush constant televisual stimulation definitely exciting like comment movielink new studio approve online movie rental service unfortunately able sign cnn need sense slap day election republicans take control senate dick gephardt step house minority leader right larry king talk winona ryder verdict take break news graphic new trailer steven soderbergh solaris today movie look forward fall get copy great dvd release tarkovsky original film russian cinema council short ago hope review mindjack new film release cory doctorow review smart mob new mindjack smart mob slashdot effect apply meatspace zeitgeist squillion like minded soul know meet pop transmetropolitan brickface break white noise balance atomic viewpoint speak voice roar righteous yes adamant organizer leader manifesto forethought issue depth look internet archive doug roberts tuck away seedy neighborhood san francisco roomful computer terabyte datum store stair street lead intimidate hallway open room foot ceiling hip ductwork ceiling right storage area single desk left baker rack tightly pack shelf hp desktop machine turn maximize space ductwork fan squeak painfully walk echoey warm warehouse space easy underwhelme realize look spin away computer copy internet today mindjack short break new issue report supernova conference doug roberts supernova ambitious conference kevin warbach organizer acknowledge outset say cram day conference day conference tout glimpse decentralized future decentralize system obvious system single point control internet perfect example entity agency control single server provide service single point failure bring system warbach see type system fundamental issue compute decade end day clear conference go thing blogge discover clive thompson blog great remind need update blogroll site doug roberts cover supernova mindjack blogge live plain eerie go los angeles february miss live blogosphere panel discussion moderate xeni jardin live blogosphere bring innovator blogging mark frauenfelder heather havrilesky evan williams susannah breslin doc searl tony pierce panel discuss birth blogging emergent tension blog traditional journalism innovation blogge video blogge audio blogging mobile blogging shift role race gender blogosphere state blog economy way blog reshape contemporary medium cross post daily relay review cool laptop bag today daily relay douglas rushkoff meet al gore suitably impressed bright open minded add cosmic thinker give credit feel like know mean kid college get wild thought world connect evolve gore find organic view reality reflect constitution united states seek enable extension enlightenment thinking practical reality new mindjack today cory doctorow william gibson justin hall super monkey ball check preview warren ellis colleen doran new graphic novel orbiter ah crap shift magazine publish issue shift pull dire situation look end real shame consistently great magazine important voice change sphere digital culture final issue week urge pick copy mindjack slashdotte fray redesign time year blog come soon deepsky post remix david bowie take trip gemini spaceship website good original worth listen realaudio link post warren ellis blog cool link mindjack bruce sterling house austin texas howard waldrop beam cory doctorow swampy old dawn time day town powerbook scorch flesh leg beam england private server fraction kansas city laurenn san francisco read chapter cory new book send airport day squat power outlet public toilet continue slashdot launch holy cow ugly mindjack contributor game reviewer justin hall write great article ethic video game journalism online journalism review print magazine cover video game electronic game co found bill kunkel kunkel describe early day recent interview extent cheerleader industry love game want want write change past year game publication web site employ low pay hobbyist easy target lavish marketing event encourage inappropriate tie game maker game critic incredible scientist discover colossal squid antartic big previous big giant squid find fully grow deep sea exploration nearly fascinating space exploration imagine like see alive interesting article note funding research discovery channel great funding available space exploration google site mention mindjack suprisingly result link like description mindjack magazine pusle show osmotic swelling digital culture norm new mindjack today josh examine online interconnect group people turn advice music art fashion book etc broad implication taste tribe justin hall review panzer dragoon orta xbox illustration btw matt hinrichs hopefully semi regular one review soul calibur syberia post mortem new mindjack nearly complete index alfred hitchcock cameo article reunderstande movie dvds internet change way watch movie new mindjack start film blog promise post try review link pleasure new mindjack ad size come soon blogge mindjack daily relay lately hope able get lot good stuff come mindjack month eye blog update apparently sidewalk austin derek powazek comment entry blackbeltjone remind incredibly good friend favorite area mr bezos read add canadian friend play flickr lately late toy mad genius ludicorp find flickr profile start mindjack group bit experiment work try integrate site mindjack sacred digital music digital age ian dawe antero alli hysteria review dvd jesse walker originally upload post don melanson flickr new issue mindjack online issue link blogging equality future melanie mcbride plus kill bill vol review jesse walker new issue mindjack online article mindjack new contributor lasica write copyright law killing field review dvds breathless russian ark z spread word idea funny thing look advertising director mindjack advertising sale experience willing work commission contract job home interested email attachment constantly look great new writer want write drop email pleased announce vrml creator visionary mark pesce join mindjack grow stable writer article redefine television insightful examination state future medium snippet early day television writer like george orwell ray bradbury fahrenheit project television instrumentality totalitarian future monolithic entity dispense propaganda occasionally watch fox news far mark thing monolithic day television number actually pass people realize understand need principle television functional definition television capture encoding transmission reception decode display move image definition apply golden age television present era definition word definition television change introduction digital production encoding transmission reception decode display technology blog play blogger new feature return normal shortly blogge lot film blog like movie check course continue write blog mindjack\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q2cfEiZ9_ZI",
        "ExecuteTime": {
          "end_time": "2024-06-01T07:18:08.912999Z",
          "start_time": "2024-06-01T07:18:08.907563Z"
        }
      },
      "source": [
        "# Filters for the pre-processor\n",
        "\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "def filter_everyone(filepath):\n",
        "    return True\n",
        "\n",
        "def filter_student(filepath):\n",
        "    filename = os.path.basename(filepath)\n",
        "    return '.Student.' in filename\n",
        "\n",
        "def filter_female(filepath):\n",
        "    filename = os.path.basename(filepath)\n",
        "    return '.female.' in filename\n",
        "\n",
        "def filter_male(filepath):\n",
        "    filename = os.path.basename(filepath)\n",
        "    return '.male.' in filename\n",
        "\n",
        "def filter_age_over_20(filepath):\n",
        "    filename = os.path.basename(filepath)\n",
        "    try:\n",
        "        age = int(filename.split('.')[2])\n",
        "        return age > 20\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def filter_age_under_20(filepath):\n",
        "    filename = os.path.basename(filepath)\n",
        "    try:\n",
        "        age = int(filename.split('.')[2])\n",
        "        return age <= 20\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "#  Helper function to work with the pre-processed data\n",
        "#  (they would be much bigger)\n",
        "def save_compressed_pickle(data, filename):\n",
        "    with gzip.open(filename, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "def load_compressed_pickle(filename):\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "outputs": [],
      "execution_count": 25
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-01T07:18:08.930244Z",
          "start_time": "2024-06-01T07:18:08.914004Z"
        },
        "id": "xq3E0US76kMh"
      },
      "cell_type": "code",
      "source": [
        "# Pre-Processing of the data from smaller to bigger ds\n",
        "# Process \"Students\"\n",
        "#text_data_students, failed_files_students = extract_and_preprocess_text_from_directory(directory_path, filter_student)\n",
        "#save_compressed_pickle(text_data_students, 'students_preprocessed.pkl.gz')\n",
        "\n",
        "# Process \"under 20s\"\n",
        "#text_data_under_20s, failed_files_under_20s = extract_and_preprocess_text_from_directory(directory_path, filter_age_under_20)\n",
        "#save_compressed_pickle(text_data_under_20s, 'under_20s_preprocessed.pkl.gz')\n",
        "\n",
        "# Process \"males\"\n",
        "#text_data_males, failed_files_males = extract_and_preprocess_text_from_directory(directory_path, filter_male)\n",
        "#save_compressed_pickle(text_data_males, 'males_preprocessed.pkl.gz')\n",
        "\n",
        "# Process \"females\"\n",
        "#text_data_females, failed_files_females = extract_and_preprocess_text_from_directory(directory_path, filter_female)\n",
        "#save_compressed_pickle(text_data_females, 'females_preprocessed.pkl.gz')\n",
        "\n",
        "# Process \"Over 20s\" - TODO\n",
        "#text_data_over_20s, failed_files_over_20s = extract_and_preprocess_text_from_directory(directory_path, filter_age_over_20)\n",
        "#save_compressed_pickle(text_data_over_20s, 'over_20s_preprocessed.pkl.gz')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-01T07:23:46.616176Z",
          "start_time": "2024-06-01T07:23:41.952413Z"
        },
        "id": "Be_-Dhjr6kMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2f1e80-f642-4eb5-8eef-557b3e828f76"
      },
      "cell_type": "code",
      "source": [
        "# Load of all pre-processed files\n",
        "students_data = load_compressed_pickle('PreProcessed/students_preprocessed.pkl.gz')\n",
        "#under_20s_data = load_compressed_pickle('under_20s_preprocessed.pkl.gz')\n",
        "#males_data = load_compressed_pickle('')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5111\n",
            "12360838\n"
          ]
        }
      ],
      "execution_count": 32
    },
    {
      "metadata": {
        "id": "SDU3M6UI6kMi"
      },
      "cell_type": "markdown",
      "source": [
        "## Topic modeling with LDA\n",
        "\n",
        "1. With students"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-01T07:46:51.480526Z",
          "start_time": "2024-06-01T07:46:10.434531Z"
        },
        "id": "NrJNMIUJ6kMi",
        "outputId": "c804d9e1-0d5e-4d44-d5c9-ee47ceaad6d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "# Topic modeling with LDA - Students\n",
        "students_tokens = [get_tokens_without_pos(doc) for doc in students_data]\n",
        "\n",
        "# Dictionary representation of all docs\n",
        "id2word = corpora.Dictionary(students_tokens)\n",
        "\n",
        "# Corpus representation of all docs\n",
        "corpus = [id2word.doc2bow(text) for text in students_tokens]\n",
        "\n",
        "lda_model = gensim.models.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    num_topics=2,\n",
        "    random_state=100,\n",
        "    chunksize=100,\n",
        "    passes=10,\n",
        "    alpha='auto',\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "print(lda_model.print_topics())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.014*\"like\" + 0.012*\"go\" + 0.009*\"get\" + 0.009*\"know\" + 0.008*\"think\" + 0.008*\"good\" + 0.007*\"time\" + 0.006*\"want\" + 0.006*\"day\" + 0.006*\"thing\"'), (1, '0.004*\"n\" + 0.004*\"time\" + 0.004*\"war\" + 0.003*\"haha\" + 0.003*\"u\" + 0.003*\"bush\" + 0.003*\"man\" + 0.002*\"den\" + 0.002*\"study\" + 0.002*\"e\"')]\n"
          ]
        }
      ],
      "execution_count": 29
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-01T08:06:49.721724Z",
          "start_time": "2024-06-01T07:53:33.401164Z"
        },
        "id": "VOHDSeEG6kMi",
        "outputId": "0016a508-8bfe-4869-d54b-62c7d166338b"
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Increase the max_length limit of SpaCy\n",
        "nlp.max_length = 1500000\n",
        "\n",
        "# Function to split text into chunks\n",
        "def split_text_into_chunks(text, max_chunk_size=1000000):\n",
        "    return [text[i:i + max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n",
        "\n",
        "# Extract tokens from pre-processed students_data\n",
        "def extract_tokens(documents):\n",
        "    return [[token for token, _ in doc] for doc in documents]\n",
        "\n",
        "documents = extract_tokens(students_data)\n",
        "\n",
        "# Create a dictionary and corpus\n",
        "id2word = corpora.Dictionary(documents)\n",
        "corpus = [id2word.doc2bow(text) for text in documents]\n",
        "\n",
        "# Build the LDA model using multicore processing\n",
        "lda_model = gensim.models.LdaMulticore(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    num_topics=2,\n",
        "    random_state=100,\n",
        "    chunksize=100,\n",
        "    passes=10,\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "# Get the top terms for each topic\n",
        "top_terms = lda_model.show_topics(num_words=5)\n",
        "topics = [term for topic in top_terms for term, _ in lda_model.show_topic(topic[0], topn=5)]\n",
        "print(\"Top Terms:\", topics)\n",
        "\n",
        "def extract_sentences_with_topics(text, topics):\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text for sent in doc.sents if any(topic in sent.text for topic in topics)]\n",
        "    return sentences\n",
        "\n",
        "# Combine all documents into a single text for sentence extraction\n",
        "combined_text = \" \".join([\" \".join(doc) for doc in documents])\n",
        "\n",
        "# Split the combined text into smaller chunks\n",
        "text_chunks = split_text_into_chunks(combined_text)\n",
        "\n",
        "# Extract sentences with topics from each chunk\n",
        "all_sentences_with_topics = []\n",
        "for chunk in text_chunks:\n",
        "    sentences_with_topics = extract_sentences_with_topics(chunk, topics)\n",
        "    all_sentences_with_topics.extend(sentences_with_topics)\n",
        "\n",
        "print(\"Total sentences with topics:\", len(all_sentences_with_topics))\n",
        "for sentence in all_sentences_with_topics:\n",
        "    print(sentence)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Terms: ['like', 'go', 'love', 'know', 'get', 'like', 'go', 'think', 'time', 'get']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "name": "python3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}